{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoBERTa",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladcioaba/vault/blob/main/RoBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jArKjpH4U8Up",
        "outputId": "f53fddef-baf8-40ac-c2f6-c85e7ecccd87"
      },
      "source": [
        "# Set correct tensorflow\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import gast as gs\n",
        "import folium as fl\n",
        "import imgaug as ig\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import platform as plat\n",
        "import tensorflow as tf\n",
        "import tkinter as tk\n",
        "import torch as th\n",
        "\n",
        "#how to check tools build versions\n",
        "print('Python Version: ', plat.python_version())\n",
        "#print('Gast Version: ',  gs.__version__)\n",
        "print('Folium Version: ',  fl.__version__)\n",
        "print('Imgaug Version: ',  ig.__version__)\n",
        "print('NumPy Version: ',  np.__version__)\n",
        "print('SciPy Version: ',  sp.__version__)\n",
        "print('Scikit-Learn Version: ',  sk.__version__)\n",
        "print('Pandas Version: ', pd.__version__)\n",
        "print('Tensorflow Version: ', tf.__version__)\n",
        "print('Tourch Version: ', th.__version__)\n",
        "#print('tkinter test', tk._test())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python Version:  3.6.9\n",
            "Folium Version:  0.8.3\n",
            "Imgaug Version:  0.2.9\n",
            "NumPy Version:  1.19.5\n",
            "SciPy Version:  1.4.1\n",
            "Scikit-Learn Version:  0.22.2.post1\n",
            "Pandas Version:  1.1.5\n",
            "Tensorflow Version:  2.4.0\n",
            "Tourch Version:  1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVaZIwzF6Dg-",
        "outputId": "683fd1c5-4ee5-4472-cb6b-2696f2066437"
      },
      "source": [
        "!git clone https://github.com/nishkalavallabhi/OneStopEnglishCorpus.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OneStopEnglishCorpus'...\n",
            "remote: Enumerating objects: 3074, done.\u001b[K\n",
            "remote: Total 3074 (delta 0), reused 0 (delta 0), pack-reused 3074\u001b[K\n",
            "Receiving objects: 100% (3074/3074), 23.50 MiB | 21.56 MiB/s, done.\n",
            "Resolving deltas: 100% (1143/1143), done.\n",
            "Checking out files: 100% (2656/2656), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib8h4WWxcUJd"
      },
      "source": [
        "# Download roberta.large model\n",
        "import os\n",
        "if not os.path.exists(\"roberta.large\"):\n",
        "  !wget https://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz && tar -xzvf roberta.large.tar.gz && rm roberta.large.tar.gz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkynkEruhG2I",
        "outputId": "4f7913c9-fc02-4925-e161-595064575c26"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq && cd fairseq && pip install --editable ./"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'fairseq' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyPMFBzFm5zR",
        "outputId": "1dd7bf91-80d1-4c49-a23a-e93df0c963c4"
      },
      "source": [
        "!pip install sacremoses\n",
        "!pip install spacy\n",
        "!pip install urllib3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.0.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (51.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xctkSigflf5M",
        "outputId": "da4cb394-cb1d-4199-8bfe-ab35366c277c"
      },
      "source": [
        "import torch\n",
        "\n",
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\n",
        "#roberta.cuda()\n",
        "roberta.eval()  # disable dropout for evaluation\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Encode a pair of sentences and make a prediction\n",
        "    tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')\n",
        "    prediction = roberta.predict('mnli', tokens).argmax().item()\n",
        "    assert prediction == 0  # contradiction\n",
        "\n",
        "    # Encode another pair of sentences\n",
        "    tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is based on BERT.')\n",
        "    prediction = roberta.predict('mnli', tokens).argmax().item()\n",
        "    assert prediction == 2  # entailment"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt2YXx14lxer",
        "outputId": "2acae833-6b21-4234-e697-b0ebc2bdd40d"
      },
      "source": [
        "# Batched prediction:\n",
        "from fairseq.data.data_utils import collate_tokens\n",
        "batch_of_pairs = [\n",
        "  ['Outside is not raining', 'Outside is raining'],\n",
        "  ['I like flowers', 'I not like flowers'],\n",
        "  ['Violets are red', 'Roses are blue'],\n",
        "  ['Mars is very far from earth.', 'Mars is very close.'],\n",
        "]\n",
        "\n",
        "batch = collate_tokens(\n",
        "  [roberta.encode(pair[0], pair[1]) for pair in batch_of_pairs], pad_idx=1\n",
        ")\n",
        "\n",
        "logprobs = roberta.predict('mnli', batch)\n",
        "print(logprobs.argmax(dim=1))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-PWc8Ndl1of"
      },
      "source": [
        "roberta.register_classification_head('new_task', num_classes=3)\n",
        "logprobs = roberta.predict('new_task', tokens)  # tensor([[-1.1050, -1.0672, -1.1245]], grad_fn=<LogSoftmaxBackward>)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkPVc54v-usq",
        "outputId": "a7fefc21-30a1-41e2-e28c-96576c5b7cd7"
      },
      "source": [
        "!!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)',\n",
              " 'Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)',\n",
              " 'Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)',\n",
              " 'Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)',\n",
              " 'Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)',\n",
              " 'Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)',\n",
              " 'Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)',\n",
              " 'Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)',\n",
              " 'Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)',\n",
              " 'Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)',\n",
              " 'Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)',\n",
              " 'Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)',\n",
              " 'Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)',\n",
              " 'Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)',\n",
              " 'Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (51.1.1)',\n",
              " 'Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)',\n",
              " 'Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)',\n",
              " 'Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)',\n",
              " 'Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.3.0)',\n",
              " 'Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)',\n",
              " 'Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)',\n",
              " '\\x1b[38;5;2m✔ Download and installation successful\\x1b[0m',\n",
              " \"You can now load the model via spacy.load('en_core_web_lg')\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxAAit_CSiwq",
        "outputId": "9125939c-5874-4f5e-fa4e-94f5faa8d6ed"
      },
      "source": [
        "\n",
        "roberta.fill_mask('The first Star wars movie came out in <mask>', topk=3)\n",
        "roberta.fill_mask('Vikram samvat calender is official in <mask>', topk=3)\n",
        "roberta.fill_mask('<mask> is the common currency of the European Union', topk=3)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(' that is the common currency of the European Union',\n",
              "  0.15524248778820038,\n",
              "  ' that'),\n",
              " (', is the common currency of the European Union', 0.10739845782518387, ','),\n",
              " (' the is the common currency of the European Union',\n",
              "  0.08384165167808533,\n",
              "  ' the')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJUhYxyqmAki",
        "outputId": "9e34b117-c89a-4578-a80a-e9d2d2372cfb"
      },
      "source": [
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.wsc', user_dir='examples/roberta/wsc')\n",
        "#roberta.cuda()\n",
        "\n",
        "roberta.disambiguate_pronoun('The _trophy_ would not fit in the brown suitcase because [it] was too big.')\n",
        "# True\n",
        "roberta.disambiguate_pronoun('The trophy would not fit in the brown _suitcase_ because [it] was too big.')\n",
        "# False\n",
        "\n",
        "roberta.disambiguate_pronoun('The city councilmen refused the demonstrators a permit because [they] feared violence.')\n",
        "# 'The city councilmen'\n",
        "roberta.disambiguate_pronoun('The city councilmen refused the demonstrators a permit because [they] advocated violence.')\n",
        "# 'demonstrators'\n",
        "\n",
        "doc = roberta.extract_features_aligned_to_words('I said, \"hello RoBERTa.\"')\n",
        "assert len(doc) == 10\n",
        "for tok in doc:\n",
        "  print('{:10}{} (...)'.format(str(tok), tok.vector[:5]))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/models/roberta/hub_interface.py:176: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  masked_index = (tokens == self.task.mask_idx).nonzero()\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| dictionary: 50265 types\n",
            "<s>       tensor([ 0.0545, -0.1485, -0.2556, -0.1266,  0.0687], grad_fn=<SliceBackward>) (...)\n",
            "I         tensor([ 0.4806, -0.7086, -1.1670,  0.3662, -0.0280], grad_fn=<SliceBackward>) (...)\n",
            "said      tensor([ 0.3193, -0.6057, -1.3547,  0.7873,  0.1528], grad_fn=<SliceBackward>) (...)\n",
            ",         tensor([-0.1532, -0.7339, -1.0375, -0.0990,  0.2457], grad_fn=<SliceBackward>) (...)\n",
            "\"         tensor([ 0.2073,  0.2253, -0.9358, -0.1680,  0.2879], grad_fn=<SliceBackward>) (...)\n",
            "hello     tensor([ 0.3492,  0.1469, -1.4918, -0.0900, -0.2172], grad_fn=<SliceBackward>) (...)\n",
            "RoBERTa   tensor([-0.2418,  0.0366, -2.6119, -0.4323,  0.8791], grad_fn=<SliceBackward>) (...)\n",
            ".         tensor([-0.3067, -0.1343, -0.7128, -0.3391,  0.3711], grad_fn=<SliceBackward>) (...)\n",
            "\"         tensor([-0.3067, -0.1343, -0.7128, -0.3391,  0.3711], grad_fn=<SliceBackward>) (...)\n",
            "</s>      tensor([ 0.2398, -0.4107, -0.0265,  0.6106,  0.5240], grad_fn=<SliceBackward>) (...)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsbSFTBuCWG2"
      },
      "source": [
        "# !wget \"https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/1502038877f6a88c225a34450793fbc3ea87eaba/download_glue_data.py\"\n",
        "# !python download_glue_data.py --data_dir glue_data --tasks all"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXRA0EPkBS4S",
        "outputId": "c85a4e4d-aee5-4c0f-922c-8381076bd0fe"
      },
      "source": [
        "label_map = {0: 'contradiction', 1: 'neutral', 2: 'entailment'}\n",
        "ncorrect, nsamples = 0, 0\n",
        "\n",
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\n",
        "roberta.eval()\n",
        "\n",
        "with open('OneStopEnglishCorpus/Sentence-Aligned/ADV-ELE.txt') as fin:\n",
        "  sent1 = fin.readline().strip()\n",
        "  sent2 = fin.readline().strip()\n",
        "  fin.readline() # spacer\n",
        "  target = 'neutral'\n",
        "  tokens = roberta.encode(sent1, sent2)\n",
        "  prediction = roberta.predict('mnli', tokens).argmax().item()\n",
        "  prediction_label = label_map[prediction]\n",
        "  ncorrect += int(prediction_label == target)\n",
        "  nsamples += 1\n",
        "\n",
        "print('| Accuracy: ', float(ncorrect)/float(nsamples))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Accuracy:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}