{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq -LSTM-Attention",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladcioaba/vault/blob/main/Seq2Seq_LSTM_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jArKjpH4U8Up",
        "outputId": "5aee4d0d-c044-4468-c171-5b4f4378934b"
      },
      "source": [
        "# Set correct tensorflow\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import gast as gs\n",
        "import folium as fl\n",
        "import imgaug as ig\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import platform as plat\n",
        "import tensorflow as tf\n",
        "import tkinter as tk\n",
        "\n",
        "#how to check tools build versions\n",
        "print('Python Version: ', plat.python_version())\n",
        "#print('Gast Version: ',  gs.__version__)\n",
        "print('Folium Version: ',  fl.__version__)\n",
        "print('Imgaug Version: ',  ig.__version__)\n",
        "print('NumPy Version: ',  np.__version__)\n",
        "print('SciPy Version: ',  sp.__version__)\n",
        "print('Scikit-Learn Version: ',  sk.__version__)\n",
        "print('Pandas Version: ', pd.__version__)\n",
        "print('Tensorflow Version: ', tf.__version__)\n",
        "#print('tkinter test', tk._test())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python Version:  3.6.9\n",
            "Folium Version:  0.8.3\n",
            "Imgaug Version:  0.2.9\n",
            "NumPy Version:  1.19.5\n",
            "SciPy Version:  1.4.1\n",
            "Scikit-Learn Version:  0.22.2.post1\n",
            "Pandas Version:  1.1.5\n",
            "Tensorflow Version:  2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwtNQLRwTMzc",
        "outputId": "bd94bf31-0c6d-4e44-cb34-649cce975dcf"
      },
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (51.1.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uBr9OeXT0zd",
        "outputId": "e760cdeb-bcd2-417c-c8e3-d841b32b04ac"
      },
      "source": [
        "!git clone https://github.com/nishkalavallabhi/OneStopEnglishCorpus.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OneStopEnglishCorpus'...\n",
            "remote: Enumerating objects: 3074, done.\u001b[K\n",
            "remote: Total 3074 (delta 0), reused 0 (delta 0), pack-reused 3074\u001b[K\n",
            "Receiving objects: 100% (3074/3074), 23.50 MiB | 27.13 MiB/s, done.\n",
            "Resolving deltas: 100% (1143/1143), done.\n",
            "Checking out files: 100% (2656/2656), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sul1u1_bIv-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMlaNhrtT4sz",
        "outputId": "77629763-2aeb-49c9-b34b-e6bf5331b937"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "w6idF7GtUDrl",
        "outputId": "41dd1ed7-cada-4309-94cb-734eb22c8b77"
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import glob\n",
        "\n",
        "#filename = \"OneStopEnglishCorpus/Texts-Together-OneCSVperFile/Amazon.csv\"\n",
        "#filename = \"OneStopEnglishCorpus/Texts-Together-OneCSVperFile/Amsterdam.csv\"\n",
        "\n",
        "\n",
        "#all_files = glob.glob(\"OneStopEnglishCorpus/Texts-Together-OneCSVperFile/*.csv\")\n",
        "all_files = ['OneStopEnglishCorpus/Sentence-Aligned/ADV-ELE.txt']\n",
        "data = []\n",
        "\n",
        "for filename in all_files:\n",
        "  with io.open(filename, 'rb') as f:\n",
        "    while True:\n",
        "      line1 = f.readline().decode()\n",
        "      line2 = f.readline().decode()\n",
        "      if not line1 or not line2:\n",
        "        break\n",
        "      f.readline() # spacer\n",
        "      data.append([line1, line2])\n",
        "\n",
        "reviews = pd.DataFrame(data, columns = ['ADV', 'ELE']) \n",
        "\n",
        "#reviews = pd.read_csv(filename, encoding='latin-1')\n",
        "print(reviews.shape)\n",
        "reviews.head()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2166, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADV</th>\n",
              "      <th>ELE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Seattle-based company has applied for its brand to be a top-level domain name (currently .com), but the South American governments argue this would prevent the use of this internet address for...</td>\n",
              "      <td>Amazon has asked for its company name to be a top-level domain name (currently .com), but the South American governments say this would stop the use of this internet address for environmental prot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Until now, the differences between commercial, governmental and other types of identity were easily distinguished in every internet address by .com, .gov and 20 other categories.\\n</td>\n",
              "      <td>Until now, the differences between commercial, governmental and other types of identity were easy to see in every internet address by the use of .com, .gov and 20 other categories.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazon has applied for dozens of new domains, including .shop, .song, .book and .kindle.\\n</td>\n",
              "      <td>Amazon has applied for many new domains, including .shop, .song, .book and .kindle.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allowing private companies to register geographical names as gTLDs to reinforce their brand strategy or to profit from the meaning of these names does not serve, in our view, the public interest, ...</td>\n",
              "      <td>Allowing private companies to register geographical names as gTLDs to profit from the meaning of these names is not, in our view, in the public interest, the Brazilian Ministry of Science and Tech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brazil said its views were endorsed last month by other members of the Amazon Cooperation Treaty (Bolivia, Colombia, Ecuador, Guyana, Suriname and Venezuela).\\n</td>\n",
              "      <td>Brazil said other members of the Amazon Cooperation Treaty support its views (Bolivia, Colombia, Ecuador, Guyana, Suriname and Venezuela).\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                       ADV                                                                                                                                                                                                      ELE\n",
              "0  The Seattle-based company has applied for its brand to be a top-level domain name (currently .com), but the South American governments argue this would prevent the use of this internet address for...  Amazon has asked for its company name to be a top-level domain name (currently .com), but the South American governments say this would stop the use of this internet address for environmental prot...\n",
              "1                     Until now, the differences between commercial, governmental and other types of identity were easily distinguished in every internet address by .com, .gov and 20 other categories.\\n                   Until now, the differences between commercial, governmental and other types of identity were easy to see in every internet address by the use of .com, .gov and 20 other categories.\\n\n",
              "2                                                                                                               Amazon has applied for dozens of new domains, including .shop, .song, .book and .kindle.\\n                                                                                                                    Amazon has applied for many new domains, including .shop, .song, .book and .kindle.\\n\n",
              "3  Allowing private companies to register geographical names as gTLDs to reinforce their brand strategy or to profit from the meaning of these names does not serve, in our view, the public interest, ...  Allowing private companies to register geographical names as gTLDs to profit from the meaning of these names is not, in our view, in the public interest, the Brazilian Ministry of Science and Tech...\n",
              "4                                         Brazil said its views were endorsed last month by other members of the Amazon Cooperation Treaty (Bolivia, Colombia, Ecuador, Guyana, Suriname and Venezuela).\\n                                                             Brazil said other members of the Amazon Cooperation Treaty support its views (Bolivia, Colombia, Ecuador, Guyana, Suriname and Venezuela).\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcwbkzVoXxij"
      },
      "source": [
        "CURRENCIES = {\n",
        "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
        "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\",}\n",
        "CURRENCY_REGEX = re.compile(\n",
        "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
        "\n",
        "EMAIL_REGEX = re.compile(\n",
        "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
        "    flags=re.IGNORECASE | re.UNICODE,)\n",
        "\n",
        "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
        "contractions =          {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\", \"i've\": \"i have\"}\n",
        "def clean_text(text, remove_stopwords = True):\n",
        "    \n",
        "    text = text.lower()\n",
        "    if True:\n",
        "        text = text.split()\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = \" \".join(new_text)\n",
        "        \n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = EMAIL_REGEX.sub(' ',text)\n",
        "    text = CURRENCY_REGEX.sub(' ',text)\n",
        "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r\"'s\\b\",\"\", text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    \n",
        "    if remove_stopwords:\n",
        "        text = text.split()\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "        text = \" \".join(text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX1boHv3X5yp",
        "outputId": "08057bac-3cb5-4e69-bab6-6d1dcc7ebf5c"
      },
      "source": [
        "cleaned_headlines = []\n",
        "cleaned_text = []\n",
        "\n",
        "#print(reviews.columns.values.tolist())\n",
        "\n",
        "for headlines in reviews['ELE']:\n",
        "    cleaned_headlines.append(clean_text(headlines, remove_stopwords=False))\n",
        "print(\"Headlines are complete. \" + str(len(headlines)))\n",
        "\n",
        "for text in reviews['ADV']:\n",
        "    cleaned_text.append(clean_text(text))\n",
        "print(\"Texts are complete. \" + str(len(text)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headlines are complete. 185\n",
            "Texts are complete. 179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "3PtVpbXJaKCx",
        "outputId": "e1e924a0-e0a8-4ef7-86d1-fd363196d4c4"
      },
      "source": [
        "import matplotlib.pyplot as plt #pip install matplotlib\n",
        "\n",
        "text_word_count = []\n",
        "headlines_word_count = []\n",
        "\n",
        "for i in cleaned_text:\n",
        "    text_word_count.append(len(i.split()))\n",
        "for i in cleaned_headlines:\n",
        "    headlines_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'ADV': text_word_count, 'ELE': headlines_word_count})\n",
        "length_df.hist(bins=15)\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hicnm49aSmn",
        "outputId": "33351dd2-e0ee-418b-df30-813dc5db33b5"
      },
      "source": [
        "count = 0\n",
        "for i in cleaned_text:\n",
        "    if(len(i.split())<=55):\n",
        "        count += 1\n",
        "print(count/len(cleaned_text))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "cuP1Fhl8aU70",
        "outputId": "9d7d5339-7c1f-48c4-ea26-ddbbed48a332"
      },
      "source": [
        "max_headlines_len=25\n",
        "max_text_len=100\n",
        "\n",
        "cleaned_text = np.array(cleaned_text)\n",
        "cleaned_headlines = np.array(cleaned_headlines)\n",
        "\n",
        "short_text=[]\n",
        "short_headlines=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):    \n",
        "    if(len(cleaned_headlines[i].split())<=max_headlines_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_headlines.append(cleaned_headlines[i])\n",
        "\n",
        "df=pd.DataFrame({'ADV':short_text,'ELE':short_headlines})\n",
        "df['ELE'] = df['ELE'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(np.array(df['ADV']), np.array(df['ELE']), test_size=0.1, random_state=0, shuffle=True)\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADV</th>\n",
              "      <th>ELE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>amazon applied dozens new domains including shop song book kindle</td>\n",
              "      <td>sostok amazon has applied for many new domains  including  shop   song   book and  kindle  eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>brazil said views endorsed last month members amazon cooperation treaty bolivia colombia ecuador guyana suriname venezuela</td>\n",
              "      <td>sostok brazil said other members of the amazon cooperation treaty support its views  bolivia  colombia  ecuador  guyana  suriname and venezuela   eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>argentina rejects patagonia request new generic top level domain government notes appeal</td>\n",
              "      <td>sostok argentina rejects the  patagonia request for a new generic top level domain  eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>patagonia relevant region countrys economy oil fishing mining agriculture resources</td>\n",
              "      <td>sostok patagonia is an important region for the countrys economy because it has oil  fishing  mining and agriculture resources  eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bartho boer spokesman mayor denies plans illiberal</td>\n",
              "      <td>sostok bartho boer  a spokesman for the mayor  says that the plans are not illiberal  eostok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                          ADV                                                                                                                                                       ELE\n",
              "0                                                           amazon applied dozens new domains including shop song book kindle                                                         sostok amazon has applied for many new domains  including  shop   song   book and  kindle  eostok\n",
              "1  brazil said views endorsed last month members amazon cooperation treaty bolivia colombia ecuador guyana suriname venezuela  sostok brazil said other members of the amazon cooperation treaty support its views  bolivia  colombia  ecuador  guyana  suriname and venezuela   eostok\n",
              "2                                    argentina rejects patagonia request new generic top level domain government notes appeal                                                                sostok argentina rejects the  patagonia request for a new generic top level domain  eostok\n",
              "3                                         patagonia relevant region countrys economy oil fishing mining agriculture resources                    sostok patagonia is an important region for the countrys economy because it has oil  fishing  mining and agriculture resources  eostok\n",
              "4                                                                          bartho boer spokesman mayor denies plans illiberal                                                              sostok bartho boer  a spokesman for the mayor  says that the plans are not illiberal  eostok"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0Z5N_6daeX7",
        "outputId": "80a98450-adf0-4400-806f-3cd60acf4689"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "thresh=4\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "print(x_voc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 71.63498098859316\n",
            "Total Coverage of rare words: 33.73049277990028\n",
            "1120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCbheaAxah3K",
        "outputId": "e9575a21-d805-4c7f-a9a8-7eaa821ebc23"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "thresh=6\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_headlines_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_headlines_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "\n",
        "y_tokenizer.word_counts['sostok'],len(y_tr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 77.85254534815682\n",
            "Total Coverage of rare words: 21.278474956758547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1476, 1476)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRVcsw6TalG8"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)\n",
        "\n",
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-eoenp-an-z",
        "outputId": "3def5010-8702-4a9e-b8d7-52074fe6b114"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 200\n",
        "embedding_dim=110\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 110)     123200      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 100, 200), ( 248800      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 100, 200), ( 320800      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 110)    83380       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 100, 200), ( 320800      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  248800      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 200),  80200       lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 400)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 758)    303958      concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,729,938\n",
            "Trainable params: 1,729,938\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l63uUEwaqOI",
        "outputId": "007ee048-d3ca-42da-fd3a-429230c7c723"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 26s 1s/step - loss: 2.5890 - val_loss: 2.4581\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.4648 - val_loss: 2.4482\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 2.3588 - val_loss: 2.4352\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 2.4104 - val_loss: 2.4404\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 2.3241 - val_loss: 2.4052\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 2.3000 - val_loss: 2.3698\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 2.2959 - val_loss: 2.3511\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.2452 - val_loss: 2.3288\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.1876 - val_loss: 2.3181\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.1719 - val_loss: 2.2940\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 2.1647 - val_loss: 2.2741\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.1030 - val_loss: 2.2572\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.0801 - val_loss: 2.2404\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.0311 - val_loss: 2.2342\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 2.0408 - val_loss: 2.2023\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.9850 - val_loss: 2.2016\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.9638 - val_loss: 2.1651\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.9416 - val_loss: 2.1400\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.8889 - val_loss: 2.1271\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.8415 - val_loss: 2.1102\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.8059 - val_loss: 2.0908\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.7635 - val_loss: 2.1101\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.7513 - val_loss: 2.0587\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.7438 - val_loss: 2.0514\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.6951 - val_loss: 2.0486\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.6803 - val_loss: 2.0024\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.6483 - val_loss: 2.0018\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.6328 - val_loss: 1.9747\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.6168 - val_loss: 1.9356\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.5920 - val_loss: 1.9383\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.5647 - val_loss: 1.8953\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.4994 - val_loss: 1.8783\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.4867 - val_loss: 1.8606\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.4555 - val_loss: 1.8345\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.4387 - val_loss: 1.8270\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.4296 - val_loss: 1.8031\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.3777 - val_loss: 1.8241\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.3763 - val_loss: 1.7656\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.3122 - val_loss: 1.7595\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.3127 - val_loss: 1.7364\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.2930 - val_loss: 1.7132\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.2552 - val_loss: 1.6981\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.2397 - val_loss: 1.6782\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.2184 - val_loss: 1.6719\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.2218 - val_loss: 1.6352\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.1734 - val_loss: 1.6305\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.1316 - val_loss: 1.6083\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 15s 1s/step - loss: 1.1354 - val_loss: 1.5872\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.0996 - val_loss: 1.5777\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 16s 1s/step - loss: 1.0990 - val_loss: 1.5578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "hAR6MXS8auZK",
        "outputId": "002ab5c6-812c-4d00-b4cd-4ee33c520225"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6zAGWt1awMb"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index\n",
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_headlines_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZypqLFMuaykX",
        "outputId": "b48ff405-cf49-4a54-eb7b-af18c3067cd7"
      },
      "source": [
        "for i in range(0,8):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: see lot people look like modern europeans light skin \n",
            "Original summary: you see a lot of pictures of these people and and they look like modern with light \n",
            "Predicted summary:  and have many people people have to have a lot of years\n",
            "\n",
            "\n",
            "Review: apple spokesman said never heard \n",
            "Original summary: an spokesman said he has never heard of \n",
            "Predicted summary:  he says the of the first of the first of the first\n",
            "\n",
            "\n",
            "Review: way make people less ill better \n",
            "Original summary: its very positive because its a that will make people less ill and and better at what they do \n",
            "Predicted summary:  its people that do that they do not work\n",
            "\n",
            "\n",
            "Review: tested levels \n",
            "Original summary: they tested the for \n",
            "Predicted summary:  the drone is example has one in 10 000 hours singh\n",
            "\n",
            "\n",
            "Review: people sensitive ice age rhinos helped kill \n",
            "Original summary: but the same people who such sensitive pictures of ice age rhinos helped to kill them all \n",
            "Predicted summary:  the drone is example has to the reduce the 1 shark in the third in the us other has\n",
            "\n",
            "\n",
            "Review: allow happen online \n",
            "Original summary: we allow this to online so why not in \n",
            "Predicted summary:  he was that he was to the of the of and\n",
            "\n",
            "\n",
            "Review: said wanted \n",
            "Original summary: the said he wanted to to become with the \n",
            "Predicted summary:  he says the of the shock\n",
            "\n",
            "\n",
            "Review: almost 6 000 people far signed online \n",
            "Original summary: almost 6 000 people have online \n",
            "Predicted summary:  the project is a key part of moroccos plans to use its to become a global solar\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}