{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq-PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxq2htnu1pEHiWHsJOn+De",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladcioaba/vault/blob/main/Seq2seq_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G6awIg-e7NU",
        "outputId": "12aaf466-83ea-45f7-e124-22145ebc4527"
      },
      "source": [
        "!git clone https://github.com/nishkalavallabhi/OneStopEnglishCorpus.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OneStopEnglishCorpus'...\n",
            "remote: Enumerating objects: 3074, done.\u001b[K\n",
            "remote: Total 3074 (delta 0), reused 0 (delta 0), pack-reused 3074\u001b[K\n",
            "Receiving objects: 100% (3074/3074), 23.50 MiB | 25.93 MiB/s, done.\n",
            "Resolving deltas: 100% (1143/1143), done.\n",
            "Checking out files: 100% (2656/2656), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIkZBdSJJbhT"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 10000\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "    super(AttnDecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dropout_p = dropout_p\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    embedded = self.dropout(embedded)\n",
        "\n",
        "    attn_weights = F.softmax(\n",
        "        self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                              encoder_outputs.unsqueeze(0))\n",
        "\n",
        "    output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "    output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "\n",
        "    output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "    return output, hidden, attn_weights\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, target_tensor)\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  input_length = input_tensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "\n",
        "  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "    encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "  decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    # Teacher forcing: Feed the target as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "  else:\n",
        "    # Without teacher forcing: use its own predictions as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item() / target_length\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "  m = math.floor(s / 60)\n",
        "  s -= m * 60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / (percent)\n",
        "  rs = es - s\n",
        "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  # this locator puts ticks at regular intervals\n",
        "  loc = ticker.MultipleLocator(base=0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "  encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "  training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  for iter in range(1, n_iters + 1):\n",
        "    training_pair = training_pairs[iter - 1]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "\n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "    if iter % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "\n",
        "  showPlot(plot_losses)\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "    input_length = input_tensor.size()[0]\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                encoder_hidden)\n",
        "      encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = []\n",
        "    decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "    for di in range(max_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      decoder_attentions[di] = decoder_attention.data\n",
        "      topv, topi = decoder_output.data.topk(1)\n",
        "      if topi.item() == EOS_token:\n",
        "        decoded_words.append('<EOS>')\n",
        "        break\n",
        "      else:\n",
        "        decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words, decoder_attentions[:di + 1]\n",
        "    \n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "  for i in range(n):\n",
        "    pair = random.choice(pairs)\n",
        "    print('>', pair[0])\n",
        "    print('=', pair[1])\n",
        "    output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    print('<', output_sentence)\n",
        "    print('')\n",
        "\n",
        "# Turn a Unicode string to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "    c for c in unicodedata.normalize('NFD', s)\n",
        "    if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s\n",
        "    \n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "  print(\"Reading lines...\")\n",
        "\n",
        "  # Read the file and split into lines\n",
        "  #lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "  # Split every line into pairs and normalize\n",
        "  #pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "  \n",
        "  pairs = []\n",
        "  f1 = open('OneStopEnglishCorpus/Sentence-Aligned/ADV-INT.txt')\n",
        "  while True:\n",
        "    line1 = f1.readline()\n",
        "    line2 = f1.readline()\n",
        "    f1.readline() # delimiter\n",
        "    if not line1 or not line2:\n",
        "      break\n",
        "    pairs.append([normalizeString(line1), normalizeString(line2)])\n",
        "  \n",
        "  #print(pairs[:10])\n",
        "  # Reverse pairs, make Lang instances\n",
        "  if reverse:\n",
        "    pairs = [list(reversed(p)) for p in pairs]\n",
        "    input_lang = Lang(lang2)\n",
        "    output_lang = Lang(lang1)\n",
        "  else:\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "  print(\"Read %s sentence pairs\" % len(pairs))\n",
        "  #pairs = filterPairs(pairs)\n",
        "  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  print(\"Counted words:\")\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name, output_lang.n_words)\n",
        "  return input_lang, output_lang, pairs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clOqyPe6JRTV",
        "outputId": "4543a810-195b-4b68-eafb-c064a38bb689"
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('eng_adv', 'env_int', False)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 2154 sentence pairs\n",
            "Trimmed to 2154 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng_adv 9248\n",
            "env_int 7980\n",
            "['the report calls for a shift in thinking about poverty to focus on the chronically poor those who are poor for many years or their entire lives and for more emphasis on stopping impoverishment the descent into poverty .', 'the report says the focus should be on the chronically poor those who are poor for many years or their entire lives and on stopping the descent into poverty .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89P3AuFLOLW3",
        "outputId": "b835bb6b-69d4-4be7-8044-141629b8615b"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7m 34s (- 106m 6s) (5000 6%) 5.5196\n",
            "15m 3s (- 97m 50s) (10000 13%) 5.1300\n",
            "22m 35s (- 90m 23s) (15000 20%) 4.7287\n",
            "30m 13s (- 83m 7s) (20000 26%) 4.2572\n",
            "37m 59s (- 75m 58s) (25000 33%) 3.8823\n",
            "45m 48s (- 68m 42s) (30000 40%) 3.6035\n",
            "53m 38s (- 61m 17s) (35000 46%) 3.3475\n",
            "61m 32s (- 53m 50s) (40000 53%) 3.2190\n",
            "69m 25s (- 46m 17s) (45000 60%) 3.1541\n",
            "77m 26s (- 38m 43s) (50000 66%) 3.0849\n",
            "85m 24s (- 31m 3s) (55000 73%) 3.0409\n",
            "93m 21s (- 23m 20s) (60000 80%) 2.9952\n",
            "101m 21s (- 15m 35s) (65000 86%) 3.0430\n",
            "109m 23s (- 7m 48s) (70000 93%) 3.0393\n",
            "117m 33s (- 0m 0s) (75000 100%) 3.0244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35UjqPmvOQh4",
        "outputId": "fb957951-ad90-485e-e493-f12be7225c34"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> he grew up on welfare and became a truck driver whereas his biological siblings and the boy brought up in his place attended private secondary schools and universities .\n",
            "= he grew up on welfare and became a truck driver whereas his biological brothers and sisters and the boy brought up in his place attended private secondary schools and universities .\n",
            "< he grew up to his biological biological biological biological biological brothers and sisters and sisters office and sisters boy up and his boy biological biological office up and his boy boy . <EOS>\n",
            "\n",
            "> even worse victims were piled too high in my stories almost dead in a fi re at pm turned out to be as few as by pm people injured in a coach crash soon became two and so it went on .\n",
            "= even worse there were too many victims in my stories almost dead in a fi re at pm turned out to be as few as by pm people injured in a coach crash soon became two and so it went on .\n",
            "< even worse there were too before too were there were there were there were there were there were there were there were there were there were there were there were were in there . <EOS>\n",
            "\n",
            "> really it is a fantasy world based in a particular time in history .\n",
            "= it is a fantasy world based in a particular time in history .\n",
            "< it is a fantasy fantasy fantasy a based in particular particular . <EOS>\n",
            "\n",
            "> radical and often ill advised changes in lifestyle have become the calling cards of the midlife crisis but if it is more than a myth then humans may not be the only animals to experience it .\n",
            "= radical and often ill advised changes in lifestyle are typical for the midlife crisis but if it is more than a myth then humans may not be the only animals to experience it .\n",
            "< radical often was advised often changes a often advised changes in lifestyle and typical to experience experience to humans experience to humans experience . <EOS>\n",
            "\n",
            "> in his office overlooking the square rjukans energetic young mayor steinar bergsland is interested not so much in the cost but in the benefits the mirrors might bring to the town .\n",
            "= in his office overlooking the square rjukans young mayor steinar bergsland is interested not so much in the cost but in the benefits the mirrors might bring to the town .\n",
            "< many lots of many of medication many of many of many of many of says few many of the town . <EOS>\n",
            "\n",
            "> greater openness with his employer and colleagues made his return to work easier .\n",
            "= more openness with his employer and colleagues made his return to work easier .\n",
            "< his openness with employer in into society to <EOS>\n",
            "\n",
            "> they emit fewer greenhouse gases and less ammonia than cows and can be grown on organic waste .\n",
            "= they produce fewer greenhouse gases and less ammonia than cows and can be grown on organic waste .\n",
            "< they produce fewer greenhouse gases than less and less than cows and less than cows and can be grown and should paying <EOS>\n",
            "\n",
            "> the good news for the economy is that of winners spending remained in the uk .\n",
            "= the good news for the economy is that of the money the winners spent remained in the uk .\n",
            "< the trip minister has the the the has the the the the . <EOS>\n",
            "\n",
            "> when its her turn maria is called forward to pick up a brown paper bag lled with essentials including pasta eggs and corn akes and is invited to choose between butternut squash or carrots as this weeks vegetables .\n",
            "= when its her turn maria goes to pick up a brown paper bag lled with essentials including pasta eggs and corn akes and can choose between butternut squash or carrots as this weeks vegetables .\n",
            "< when her maria maria a pick up a pick with paper up pick a brown paper bag she said her brown to pick with paper facebook essentials facebook essentials brown to corn . <EOS>\n",
            "\n",
            "> as a result of growing up in the digital age they are developing fundamentally different communication habits from older generations even compared to what we call the early adopters the to age group .\n",
            "= as a result of growing up in the digital age they are developing completely different communication habits from older generations even compared to the to age group .\n",
            "< he result result result of result result that result result to digital inequality to digital inequality to the inequality of the inequality they are completely to the the the the <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soNfNYflI2H7"
      },
      "source": [
        "output_words, attentions = evaluate(encoder1, attn_decoder1, \"he is one of a new wave of entrepreneurs who are turning to the fast growing crowdfunding industry for money .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mDa6t4UI4KN"
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "  # Set up figure with colorbar\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Set up axes\n",
        "  ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
        "  ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "  # Show label at every tick\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "  output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
        "  print('input =', input_sentence)\n",
        "  print('output =', ' '.join(output_words))\n",
        "  showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"Otherwise no devil would have built a city here\")\n",
        "#evaluateAndShowAttention(\"we are all in favour of anything that makes the referees job better and makes them more effective on the field of play says riley .\")\n",
        "#evaluateAndShowAttention(\"he is one of a new wave of entrepreneurs turning to the fast growing crowdfunding industry for finance .\")\n",
        "#evaluateAndShowAttention(\"we are starting with pizzaexpress but they are by no means the only offender and we will be turning our attention to other companies after this .\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}